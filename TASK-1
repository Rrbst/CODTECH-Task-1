This code implements a Generative Adversarial Network (GAN) using the Fashion MNIST dataset, which consists of grayscale images of clothing items. Let's break it down step by step:

1. Data Loading and Preprocessing:
The dataset is provided in a zip file (fashion-mnist_test.csv.zip). The zip file is extracted, and the Fashion MNIST CSV file is loaded using pandas.
The labels are separated from the pixel data. The pixel data (X_train) is reshaped to have the shape (num_samples, 28, 28, 1) (i.e., 28x28 images with 1 color channel).
The pixel values are normalized to a range of [0, 1] by dividing by 255.0 (since original pixel values are from 0 to 255).
2. Building the Generator Model:
The Generator generates new images from random noise. It uses a fully connected neural network structure.
The layers in the generator include:
Dense layers followed by Leaky ReLU activations and Batch Normalization to stabilize training.
The final output layer reshapes the output to a 28x28x1 image with a tanh activation (output values range from -1 to 1).
Generator Architecture:

Input: A random noise vector (100-dimensional).
Hidden layers: 256, 512, and 1024 units, each followed by a Leaky ReLU activation and Batch Normalization.
Output layer: A single 28x28 image.
3. Building the Discriminator Model:
The Discriminator distinguishes between real and fake images. It classifies images as real (from the dataset) or fake (generated by the Generator).
The layers in the discriminator include:
Flatten the image input (28x28x1).
Dense layers with Leaky ReLU activations.
Output layer with a sigmoid activation function, which gives a binary output (real or fake).
Discriminator Architecture:

Input: A 28x28x1 image.
Hidden layers: 512 and 256 units with Leaky ReLU activations.
Output layer: Single unit with sigmoid activation.
4. Compiling the Models:
The Discriminator is compiled with binary cross-entropy loss and the Adam optimizer.
The Generator is compiled indirectly through the combined model.
The combined model (GAN) consists of both the Generator and Discriminator:

The Generator generates images from random noise.
The Discriminator classifies these images as real or fake.
The Discriminator is frozen during the training of the Generator, meaning it won't be updated during this phase.
5. Training the GAN:
The training function train_gan runs the training loop for a given number of epochs.
Discriminator Training:
A batch of real images is selected from the dataset.
A batch of fake images is generated by the Generator using random noise.
The Discriminator is trained on both real and fake images, updating its weights to distinguish between them.
Generator Training:
The Generator is trained to produce images that the Discriminator classifies as real.
The Discriminator is kept frozen during the Generatorâ€™s training.
The train_on_batch method is used to train both models one batch at a time.
The training loop prints the losses of both the Discriminator (D loss) and the Generator (G loss) at each epoch, providing feedback on the progress of training.

6. Saving Generated Images:
Every save_interval epochs, the save_images function is called to generate and display images.
Random noise is passed through the Generator to generate new images, which are rescaled to the range [0, 1] for visualization.
These images are displayed using matplotlib in a grid of examples generated images.
7. Training the GAN:
The GAN is trained for 10,000 epochs, with a batch size of 64. Every 1,000 epochs, generated images are saved and displayed







import os
import zipfile
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Flatten, Reshape, LeakyReLU, BatchNormalization, Conv2DTranspose, Conv2D

# Unzip the uploaded file
file_path = 'fashion-mnist_test.csv.zip'
unzipped_path = 'fashion-mnist_test[1].csv'

with zipfile.ZipFile(file_path, 'r') as zip_ref:
    zip_ref.extractall('/mnt/data/')

# Load the Fashion MNIST dataset
fashion_mnist = pd.read_csv(unzipped_path)

# Separate labels from pixel data (assuming first column is the label)
X_train = fashion_mnist.iloc[:, 1:].values  # Drop the first column (labels)
X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0  # Normalize to [0, 1]

print(f"Shape of X_train: {X_train.shape}")  # Print to verify the shape

# Define the Generator model
def build_generator():
    model = Sequential()
    model.add(Dense(256, input_dim=100))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(512))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(1024))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(28 * 28 * 1, activation='tanh'))  # The output size is 28x28x1
    model.add(Reshape((28, 28, 1)))
    return model

# Define the Discriminator model
def build_discriminator():
    model = Sequential()
    model.add(Flatten(input_shape=(28, 28, 1)))
    model.add(Dense(512))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(1, activation='sigmoid'))  # Binary classification (Real/Fake)
    return model

# Compile the Discriminator
discriminator = build_discriminator()
discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])

generator = build_generator()

# Create the combined GAN model (Generator + Discriminator)
z = tf.keras.Input(shape=(100,))  # Random noise input to the generator
fake_image = generator(z)
discriminator.trainable = False  # Freeze the discriminator during generator training
validity = discriminator(fake_image)
combined = Model(z, validity)
combined.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))

# Training the GAN
def train_gan(epochs, batch_size=64, save_interval=100):
    
    valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))
    
    for epoch in range(epochs):
        
        # Train the Discriminator
        idx = np.random.randint(0, X_train.shape[0], batch_size)
        real_images = X_train[idx]
        
        noise = np.random.normal(0, 1, (batch_size, 100))  # Random noise for the generator
        generated_images = generator.predict(noise)
        
        d_loss_real = discriminator.train_on_batch(real_images, valid)
        d_loss_fake = discriminator.train_on_batch(generated_images, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
        
        # Train the Generator
        noise = np.random.normal(0, 1, (batch_size, 100))
        g_loss = combined.train_on_batch(noise, valid)
        
        # Print the progress
        print(f"Epoch {epoch+1}/{epochs} [D loss: {d_loss[0]:.4f}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]")
        
        # Save generated images every 'save_interval' epochs
        if epoch % save_interval == 0:
            save_images(epoch)

# Function to save images generated by the Generator
def save_images(epoch, examples=10):
    noise = np.random.normal(0, 1, (examples, 100))
    generated_images = generator.predict(noise)
    
    # Rescale images to [0, 1] for visualization
    generated_images = 0.5 * generated_images + 0.5  
    fig, axs = plt.subplots(1, examples, figsize=(20, 4))
    for i in range(examples):
        axs[i].imshow(generated_images[i, :, :, 0], cmap='gray')
        axs[i].axis('off')
    plt.show()

# Train the GAN
epochs = 10000  # Number of epochs to train the GAN
batch_size = 64  # Batch size
save_interval = 1000  # Save interval for generating and saving images

# Call the training function
train_gan(epochs, batch_size, save_interval)  # Training the GAN model

CODE 2 : GENERATE IMAGES RESEMBLING

This code defines and trains a Generative Adversarial Network (GAN) to generate images resembling a given input image, in this case, "flowers.jpg." Here's a brief explanation:

Image Preprocessing:

The input image is loaded and resized to 64x64 pixels.
It is normalized to a range between 0 and 1 for better neural network training.
Generator Model:

The generator takes a random noise vector (latent space) and generates images resembling the input image using several layers like Dense, Conv2DTranspose, and BatchNormalization.
Discriminator Model:

The discriminator distinguishes between real and generated images. It uses Conv2D layers for feature extraction and a Dense layer for binary classification (real or fake).
GAN Setup:

The generator and discriminator are combined to form the GAN. The discriminator is frozen during generator training.
The GAN is compiled with a binary cross-entropy loss function and the Adam optimizer.
Training Loop:

In each epoch, the discriminator is trained on both real and generated images. The generator is trained to fool the discriminator into classifying generated images as real.
The losses for both the discriminator and generator are printed during training.
Every 100 epochs, generated images are saved and displayed.
Image Generation:

After training, the generator can be used to generate new images by feeding it random noise vectors.
This process allows the GAN to learn how to generate realistic images similar to the input image.



import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Reshape, Flatten, LeakyReLU, Conv2DTranspose, Conv2D, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# 1. Load and preprocess the image
def load_and_preprocess_image(image_path, img_size=(64, 64)):
    img = load_img(image_path, target_size=img_size)
    img_array = img_to_array(img)
    img_array = img_array / 255.0  # Normalize to [0, 1]
    return img_array

# Load the input image
image_path = 'flowers.jpg'
img_size = (64, 64)  # Resize images for GAN input
image_data = load_and_preprocess_image(image_path, img_size)
image_data = np.expand_dims(image_data, axis=0)  # Add batch dimension

print(f"Image shape: {image_data.shape}")  # Verify shape

# 2. Define the Generator model
def build_generator(latent_dim):
    model = Sequential()
    model.add(Dense(8 * 8 * 128, input_dim=latent_dim))
    model.add(LeakyReLU(0.2))
    model.add(Reshape((8, 8, 128)))
    
    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))
    model.add(LeakyReLU(0.2))
    model.add(BatchNormalization())
    
    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))
    model.add(LeakyReLU(0.2))
    model.add(BatchNormalization())
    
    model.add(Conv2DTranspose(3, kernel_size=4, strides=2, activation='tanh', padding='same'))
    return model

# 3. Define the Discriminator model
def build_discriminator(img_shape):
    model = Sequential()
    model.add(Conv2D(64, kernel_size=4, strides=2, input_shape=img_shape, padding='same'))
    model.add(LeakyReLU(0.2))
    
    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))
    model.add(LeakyReLU(0.2))
    
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    return model

# 4. Compile the models
latent_dim = 100
img_shape = (64, 64, 3)

generator = build_generator(latent_dim)
discriminator = build_discriminator(img_shape)
discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])

# Combined model
discriminator.trainable = False
gan_input = tf.keras.Input(shape=(latent_dim,))
generated_img = generator(gan_input)
gan_output = discriminator(generated_img)
gan = Model(gan_input, gan_output)
gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))

# 5. Train the GAN
def train_gan(epochs, batch_size):
    valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))
    
    for epoch in range(epochs):
        # Train Discriminator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        generated_images = generator.predict(noise)
        
        real_images = np.tile(image_data, (batch_size, 1, 1, 1))  # Duplicate input image
        d_loss_real = discriminator.train_on_batch(real_images, valid)
        d_loss_fake = discriminator.train_on_batch(generated_images, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
        
        # Train Generator
        g_loss = gan.train_on_batch(noise, valid)
        
        print(f"Epoch {epoch+1}/{epochs} [D loss: {d_loss[0]:.4f}, acc.: {100*d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]")
        
        if epoch % 100 == 0:
            save_images(epoch, generator)

# 6. Save and visualize generated images
def save_images(epoch, generator, examples=1):
    noise = np.random.normal(0, 1, (examples, latent_dim))
    generated_images = generator.predict(noise)
    generated_images = 0.5 * generated_images + 0.5  # Rescale to [0, 1]
    
    for i in range(examples):
        plt.imshow(generated_images[i])
        plt.axis('off')
        plt.show()

# Train the GAN
train_gan(epochs=2500, batch_size=4)

